{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solar calculator is [Apogee Instrument's Clear Sky Calculator](http://clearskycalculator.com/quantumsensor.htm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The day length is calculated from a Excel Workbook from NOAA. The original is located at [NOAA's Solar Calculations](https://www.esrl.noaa.gov/gmd/grad/solcalc/NOAA_Solar_Calculations_year.xls)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries\n",
    "Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T22:54:05.209787Z",
     "start_time": "2021-01-26T22:54:05.205800Z"
    }
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import datetime as dt\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from dateutil import tz\n",
    "\n",
    "import webbrowser\n",
    "\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location and General Settings\n",
    "Choose latitude and longitude location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T22:54:05.608880Z",
     "start_time": "2021-01-26T22:54:05.605879Z"
    }
   },
   "outputs": [],
   "source": [
    "Latitude = 40.7\n",
    "Longitude = -111.9 # - to W for Sunrise/Sunset Calculator and + to W for Apogee Calulator (code adjusts for this)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If Latitude and Longitude are unknown can use the webpage below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T22:54:06.116991Z",
     "start_time": "2021-01-26T22:54:06.085975Z"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://itouchmap.com/?r=latlong'\n",
    "webbrowser.open(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local UTC offset (+ to East) and year for day durations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T22:54:10.592954Z",
     "start_time": "2021-01-26T22:54:10.588957Z"
    }
   },
   "outputs": [],
   "source": [
    "utc = -7\n",
    "year = 2020\n",
    "local_time = '12:00:00'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If UTC offset is unkown use the webpage below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T21:23:30.361719Z",
     "start_time": "2021-01-26T21:23:30.334711Z"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_UTC_time_offsets'\n",
    "webbrowser.open(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you desire to see daylight savings time enter yes or no and the dates below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T22:54:12.393324Z",
     "start_time": "2021-01-26T22:54:12.390335Z"
    }
   },
   "outputs": [],
   "source": [
    "daylight_savings = 'No'\n",
    "start_day = '2020-01-02' # add after\n",
    "end_day = '2020-11-01'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elevation (m) and longitude of time zone. For more info see [here](http://clearskycalculator.com/longitudeTZ.htm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T22:54:15.864043Z",
     "start_time": "2021-01-26T22:54:15.861050Z"
    }
   },
   "outputs": [],
   "source": [
    "Longitude_tz = 105\n",
    "Elevation = 1291"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If Longitude_tz is unknown use the webpage below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T21:22:13.541992Z",
     "start_time": "2021-01-26T21:22:13.510991Z"
    }
   },
   "outputs": [],
   "source": [
    "url = 'http://clearskycalculator.com/longitudeTZ.htm'\n",
    "webbrowser.open(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose location name for filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T22:54:18.879658Z",
     "start_time": "2021-01-26T22:54:18.876665Z"
    }
   },
   "outputs": [],
   "source": [
    "location = 'LoganUT'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select if hourly average climate values are being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T22:54:19.658827Z",
     "start_time": "2021-01-26T22:54:19.654820Z"
    }
   },
   "outputs": [],
   "source": [
    "hourly_averages = 'Yes'\n",
    "hourly_averages_filename = 'Hourly_Averages_SaltLake' # Must be csv file\n",
    "hourly_location_averages = 'SaltLakeCity'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select if daily average climate values are being used (currently unsupported and being developed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T22:54:20.391972Z",
     "start_time": "2021-01-26T22:54:20.388973Z"
    }
   },
   "outputs": [],
   "source": [
    "# daily_averages = 'No'\n",
    "# daily_averages_filename = 'Daily_Averages_Logan' # Must be csv file\n",
    "# daily_location_averages = 'Logan'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If looking for averages to download (both hourly and daily). These will contain the proper formatting for the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T22:42:34.222427Z",
     "start_time": "2021-01-26T22:42:34.189432Z"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://www.ncdc.noaa.gov/cdo-web/search'\n",
    "webbrowser.open(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to Run\n",
    "Functions relevant to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T22:54:23.609636Z",
     "start_time": "2021-01-26T22:54:23.605627Z"
    }
   },
   "outputs": [],
   "source": [
    "def time_to_decimal(time):\n",
    "    # Takes in a time format as a string such as 12:00:00\n",
    "    # Returns a decimal time\n",
    "    x = time.split(\":\")\n",
    "    h = int(x[0])/24\n",
    "    m = int(x[1])/(24*60)\n",
    "    s = int(x[2])/(24*60*60)\n",
    "    time = h + m + s\n",
    "    return time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T22:54:23.967713Z",
     "start_time": "2021-01-26T22:54:23.964718Z"
    }
   },
   "outputs": [],
   "source": [
    "def decimal_to_time(time):\n",
    "    # Takes in a decimal time format\n",
    "    # Returns a string time such as 12:00:00\n",
    "    time = time * 24\n",
    "    hours = int(time)\n",
    "    minutes = (time*60) % 60\n",
    "    seconds = (time*3600) % 60\n",
    "      \n",
    "    return \"%d:%02d:%02d\" % (hours, minutes, seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T22:54:24.319788Z",
     "start_time": "2021-01-26T22:54:24.316794Z"
    }
   },
   "outputs": [],
   "source": [
    "def tz_offset(time, offset):\n",
    "    time = time.split(\":\")\n",
    "    hour = int(time[0]) + offset\n",
    "    return \"%d:%02d:%02d\" % (hour, int(time[1]), int(time[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T22:54:24.730871Z",
     "start_time": "2021-01-26T22:54:24.723883Z"
    }
   },
   "outputs": [],
   "source": [
    "def Hourly_Normals(date_time, hourly_averages, weather_model):\n",
    "    # Must be called after creating webdriver object and import hourly normals\n",
    "    \n",
    "    #Get 30 Year Average Values\n",
    "    Temp_90th = hourly_averages.loc[date_time]['HLY-TEMP-90PCTL']\n",
    "    Temp_mean = hourly_averages.loc[date_time]['HLY-TEMP-NORMAL']\n",
    "    Temp_10th = hourly_averages.loc[date_time]['HLY-TEMP-10PCTL']\n",
    "    Dew_90th = hourly_averages.loc[date_time]['HLY-DEWP-90PCTL']\n",
    "    Dew_Mean = hourly_averages.loc[date_time]['HLY-DEWP-NORMAL']\n",
    "    Dew_10th = hourly_averages.loc[date_time]['HLY-DEWP-10PCTL']\n",
    "    Clouds_Broken = hourly_averages.loc[date_time]['HLY-CLOD-PCTBKN']\n",
    "    Clouds_Clear = hourly_averages.loc[date_time]['HLY-CLOD-PCTCLR']\n",
    "    Clouds_Scattered = hourly_averages.loc[date_time]['HLY-CLOD-PCTSCT']\n",
    "    Clouds_Overcast = hourly_averages.loc[date_time]['HLY-CLOD-PCTOVC']\n",
    "    Clouds_Few = hourly_averages.loc[date_time]['HLY-CLOD-PCTFEW']\n",
    "\n",
    "    #Calculate relative humidity\n",
    "    Rel_Hum = 100*(math.exp((17.625*Dew_Mean)/(243.04+Dew_Mean))/math.exp((17.625*Temp_mean)/(243.04+Temp_mean)))\n",
    "\n",
    "    #Calculate Estimated PPF\n",
    "    Time_Input.send_keys(Keys.CONTROL,\"a\")\n",
    "    Time_Input.send_keys(str(hour))\n",
    "    Air_Temperature_Input.send_keys(Keys.CONTROL,\"a\")\n",
    "    Air_Temperature_Input.send_keys(str(Temp_mean))\n",
    "    Relative_Humidity.send_keys(Keys.CONTROL,\"a\")\n",
    "    Relative_Humidity.send_keys(str(Rel_Hum))\n",
    "    Recalculate.click()\n",
    "    Est_PPF = Estimated_PPF.get_attribute('value')\n",
    "    \n",
    "    #Add row to weather model dataframe\n",
    "    weather_model.loc[len(weather_model.index)] = [date_time,Light,Dark,Est_PPF,Temp_90th,Temp_mean,Temp_10th,Dew_90th,Dew_Mean,Dew_10th,Clouds_Broken,Clouds_Clear,Clouds_Scattered,Clouds_Overcast,Clouds_Few,Rel_Hum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T22:54:25.307992Z",
     "start_time": "2021-01-26T22:54:25.301993Z"
    }
   },
   "outputs": [],
   "source": [
    "def Hourly_Normals_Offset(date_time, hourly_averages, weather_model, offset):\n",
    "    # Used to fill holes in data by creating daily of hourly offsets and assuming weather normals will be similar\n",
    "    \n",
    "    # Must be called after creating webdriver object and import hourly normals\n",
    "    date_time_off = date_time + offset \n",
    "    \n",
    "    #Get 30 Year Average Values\n",
    "    Temp_90th = hourly_averages.loc[date_time_off]['HLY-TEMP-90PCTL']\n",
    "    Temp_mean = hourly_averages.loc[date_time_off]['HLY-TEMP-NORMAL']\n",
    "    Temp_10th = hourly_averages.loc[date_time_off]['HLY-TEMP-10PCTL']\n",
    "    Dew_90th = hourly_averages.loc[date_time_off]['HLY-DEWP-90PCTL']\n",
    "    Dew_Mean = hourly_averages.loc[date_time_off]['HLY-DEWP-NORMAL']\n",
    "    Dew_10th = hourly_averages.loc[date_time_off]['HLY-DEWP-10PCTL']\n",
    "    Clouds_Broken = hourly_averages.loc[date_time_off]['HLY-CLOD-PCTBKN']\n",
    "    Clouds_Clear = hourly_averages.loc[date_time_off]['HLY-CLOD-PCTCLR']\n",
    "    Clouds_Scattered = hourly_averages.loc[date_time_off]['HLY-CLOD-PCTSCT']\n",
    "    Clouds_Overcast = hourly_averages.loc[date_time_off]['HLY-CLOD-PCTOVC']\n",
    "    Clouds_Few = hourly_averages.loc[date_time_off]['HLY-CLOD-PCTFEW']\n",
    "\n",
    "    #Calculate relative humidity\n",
    "    Rel_Hum = 100*(math.exp((17.625*Dew_Mean)/(243.04+Dew_Mean))/math.exp((17.625*Temp_mean)/(243.04+Temp_mean)))\n",
    "\n",
    "    #Calculate Estimated PPF\n",
    "    Time_Input.send_keys(Keys.CONTROL,\"a\")\n",
    "    Time_Input.send_keys(str(hour))\n",
    "    Air_Temperature_Input.send_keys(Keys.CONTROL,\"a\")\n",
    "    Air_Temperature_Input.send_keys(str(Temp_mean))\n",
    "    Relative_Humidity.send_keys(Keys.CONTROL,\"a\")\n",
    "    Relative_Humidity.send_keys(str(Rel_Hum))\n",
    "    Recalculate.click()\n",
    "    Est_PPF = Estimated_PPF.get_attribute('value')\n",
    "    \n",
    "    #Add row to weather model dataframe\n",
    "    weather_model.loc[len(weather_model.index)] = [date_time,Light,Dark,Est_PPF,Temp_90th,Temp_mean,Temp_10th,Dew_90th,Dew_Mean,Dew_10th,Clouds_Broken,Clouds_Clear,Clouds_Scattered,Clouds_Overcast,Clouds_Few,Rel_Hum]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solar Position Calculator\n",
    "Calculates sunrise/sunset and other solar position values based on Astromonomical Algortithms by Jean Meeus. Formulas were adapted from a National Oceanic and Atomospheric Adminstration [Excel sheet](https://www.esrl.noaa.gov/gmd/grad/solcalc/calcdetails.html). Further details can be found in the Github README or at the link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T22:54:28.795735Z",
     "start_time": "2021-01-26T22:54:28.093571Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create dataframe\n",
    "sol = pd.DataFrame(columns=['Date'])\n",
    "\n",
    "# Create date range index\n",
    "start = str(year)+'-01-01'\n",
    "end = str(year)+'-12-31'\n",
    "start = datetime.strptime(start, '%Y-%m-%d')\n",
    "end = datetime.strptime(end, '%Y-%m-%d')\n",
    "step = timedelta(days=1)\n",
    "while start <= end:\n",
    "    sol.loc[len(sol.index)] = [start]\n",
    "    start += step\n",
    "\n",
    "# Add local time\n",
    "sol['Time'] = local_time\n",
    "\n",
    "# Julian Day\n",
    "base = '1900-01-01'\n",
    "base = datetime.strptime(base, '%Y-%m-%d')\n",
    "sol['Julian_Day'] = (sol['Date'] - base + dt.timedelta(\n",
    "    days=2)).astype('timedelta64[D]') + 2415018.5+time_to_decimal(local_time)-utc/24\n",
    "\n",
    "# Julian Century\n",
    "sol['Julian_Century'] = (\n",
    "    sol['Julian_Day']-2451545)/36525\n",
    "\n",
    "# Geom Mean Long Sun (deg)\n",
    "sol['Geom_Mean_Long_Sun(deg)'] = (280.46646+sol['Julian_Century']*(\n",
    "    36000.76983 + sol['Julian_Century']*0.0003032)) % 360\n",
    "\n",
    "# Geom Mean Anom Sun (deg)\n",
    "sol['Geom_Mean_Anom_Sun(deg)'] = 357.52911+sol['Julian_Century']*(\n",
    "    35999.05029 - 0.0001537*sol['Julian_Century'])\n",
    "\n",
    "# Eccent Earth Orbit\n",
    "sol['Eccent_Earth_Orbit'] = 0.016708634-sol['Julian_Century'] * \\\n",
    "    (0.000042037+0.0000001267*sol['Julian_Century'])\n",
    "\n",
    "# Sun Eq of Ctr\n",
    "sol['Sun_Eq_of_Ctr'] = np.sin(np.radians(sol['Geom_Mean_Anom_Sun(deg)'])\n",
    "                       )*(1.914602-sol['Julian_Century']*(0.004817+0.000014\n",
    "                        *sol['Julian_Century']))+np.sin(np.radians(2*sol['Geom_Mean_Anom_Sun(deg)']\n",
    "                        ))*(0.019993-0.000101*sol['Julian_Century'])+np.sin(np.radians(3*\n",
    "                        sol['Geom_Mean_Anom_Sun(deg)']))*0.000289\n",
    "\n",
    "# Sun True Long (deg)\n",
    "sol['Sun_True_Long(deg)'] = sol['Sun_Eq_of_Ctr'] + \\\n",
    "    sol['Geom_Mean_Long_Sun(deg)']\n",
    "\n",
    "# Sun True Anom (deg)\n",
    "sol['Sun_True_Anom(deg)'] = sol['Sun_Eq_of_Ctr'] + \\\n",
    "    sol['Geom_Mean_Anom_Sun(deg)']\n",
    "\n",
    "# Sun Rad Vector (AUs)\n",
    "sol['Sun_Rad_Vector(AUs)'] = (1.000001018*(1-sol['Eccent_Earth_Orbit']*sol['Eccent_Earth_Orbit'])\n",
    "                              )/(1+sol['Eccent_Earth_Orbit']*np.cos(np.radians(sol['Sun_True_Anom(deg)'])))\n",
    "\n",
    "# Sun App Long(deg)\n",
    "sol['Sun_App_Long(deg)'] = sol['Sun_True_Long(deg)']-0.00569 - \\\n",
    "    0.00478*np.sin(np.radians(125.04-1934.136*sol['Julian_Century']))\n",
    "\n",
    "# Mean Obliq Ecliptic (deg)\n",
    "sol['Mean_Obliq_Ecliptic(deg)'] = 23+(26+((21.448-sol['Julian_Century']*(\n",
    "    46.815+sol['Julian_Century']*(0.00059-sol['Julian_Century']*0.001813))))/60)/60\n",
    "\n",
    "# Obliq Corr(deg)\n",
    "sol['Obliq_Corr(deg)'] = sol['Mean_Obliq_Ecliptic(deg)']+0.00256 * \\\n",
    "    np.cos(np.radians(125.04-1934.136*sol['Julian_Century']))\n",
    "\n",
    "# Sun Rt Ascen(deg)\n",
    "sol['Sun_Rt_Ascen(deg)'] = np.degrees(np.arctan2(np.cos(np.radians(sol['Obliq_Corr(deg)']))\n",
    "                        * np.sin(np.radians(sol['Sun_App_Long(deg)'])), np.cos(np.radians(sol['Sun_App_Long(deg)']))))\n",
    "\n",
    "# Sun Declin(deg)\n",
    "sol['Sun_Declin(deg)'] = np.degrees(np.arcsin(np.sin(np.radians(\n",
    "    sol['Obliq_Corr(deg)']))*np.sin(np.radians(sol['Sun_App_Long(deg)']))))\n",
    "\n",
    "# var y\n",
    "sol['var_y'] = np.tan(np.radians(sol['Obliq_Corr(deg)']/2)) * \\\n",
    "    np.tan(np.radians(sol['Obliq_Corr(deg)']/2))\n",
    "\n",
    "# Eq of Time(minutes)\n",
    "sol['Eq_of_Time(min)'] = 4*np.degrees(sol['var_y']*np.sin(2*np.radians(sol['Geom_Mean_Long_Sun(deg)']))\n",
    "                            -2*sol['Eccent_Earth_Orbit']*np.sin(np.radians(sol['Geom_Mean_Anom_Sun(deg)']))\n",
    "                            +4*sol['Eccent_Earth_Orbit']*sol['var_y']*np.sin(np.radians(\n",
    "                            sol['Geom_Mean_Anom_Sun(deg)']))*np.cos(2*np.radians(sol['Geom_Mean_Long_Sun(deg)']))\n",
    "                            -0.5*sol['var_y']*sol['var_y']*np.sin(4*np.radians(sol['Geom_Mean_Long_Sun(deg)']))\n",
    "                            -1.25*sol['Eccent_Earth_Orbit']*sol['Eccent_Earth_Orbit']*np.sin(2*np.radians(\n",
    "                            sol['Geom_Mean_Anom_Sun(deg)'])))\n",
    "\n",
    "# HA Sunrise(deg)\n",
    "sol['HA_Sunrise(deg)'] = np.degrees(np.arccos(np.cos(math.radians(90.833))/(np.cos(math.radians(Latitude))\n",
    "                        *np.cos(np.radians(sol['Sun_Declin(deg)'])))-np.tan(math.radians(Latitude))\n",
    "                        *np.tan(np.radians(sol['Sun_Declin(deg)']))))\n",
    "\n",
    "# Solar Noon(LST)\n",
    "sol['Solar_Noon(LST)'] = (720-4*Longitude-sol['Eq_of_Time(min)']+utc*60)/1440\n",
    "sol['Solar_Noon(LST)'] = [decimal_to_time(x) for x in sol['Solar_Noon(LST)']]\n",
    "\n",
    "# Sunrise Time(LST)\n",
    "sol['Sunrise_Time(LST)'] = [time_to_decimal(x) for x in sol['Solar_Noon(LST)']]\n",
    "sol['Sunrise_Time(LST)'] = (sol['Sunrise_Time(LST)']*1440-sol['HA_Sunrise(deg)']*4)/1440\n",
    "sol['Sunrise_Time(LST)'] = [decimal_to_time(x) for x in sol['Sunrise_Time(LST)']]\n",
    "\n",
    "# Sunset Time(LST)\n",
    "sol['Sunset_Time(LST)'] = [time_to_decimal(x) for x in sol['Solar_Noon(LST)']]\n",
    "sol['Sunset_Time(LST)'] = (sol['Sunset_Time(LST)']*1440+sol['HA_Sunrise(deg)']*4)/1440\n",
    "sol['Sunset_Time(LST)'] = [decimal_to_time(x) for x in sol['Sunset_Time(LST)']]\n",
    "\n",
    "# Sunlight Duration(min)\n",
    "sol['Sunlight_Duration(min)'] = sol['HA_Sunrise(deg)']*8\n",
    "\n",
    "# Dark Duration(min)\n",
    "sol['Dark_Duration(min)'] = 24*60 - sol['Sunlight_Duration(min)']\n",
    "\n",
    "# True Solar Time(min)\n",
    "sol['True_Solar_Time(min)'] = (time_to_decimal(local_time)*1440+sol['Eq_of_Time(min)']+4*Longitude-60*utc) % 1440\n",
    "\n",
    "# Hour Angle(deg)\n",
    "# if sol['True_Solar_Time(min)']/4<0 then ['True_Solar_Time(min)']/4-180\n",
    "sol['Hour_Angle(deg)'] = sol['True_Solar_Time(min)'].apply(lambda x: (x/4+180) if (x/4)<0 else (x/4-180))\n",
    "\n",
    "# Solar Zenith Angle(deg)\n",
    "sol['Solar_Zenith_Angle(deg)'] = np.degrees(np.arccos(math.sin(math.radians(Latitude))*np.sin(np.radians(sol['Sun_Declin(deg)']))\n",
    "                        +math.cos(math.radians(Latitude))*np.cos(np.radians(sol['Sun_Declin(deg)']))*np.cos(np.radians(\n",
    "                            sol['Hour_Angle(deg)']))))\n",
    "\n",
    "# Solar Elevation Angle(deg)\n",
    "sol['Solar_Elevation_Angle(deg)'] = 90 - sol['Solar_Zenith_Angle(deg)']\n",
    "\n",
    "# Approx Atmospheric Refraction                                                                                        (-20.772/np.tan(np.radians(z)))))))))/3600\n",
    "sol['Approx_Atomospheric_Refraction'] = np.nan\n",
    "sol.loc[sol['Solar_Elevation_Angle(deg)'] > 85, 'Approx_Atomospheric_Refraction'] = 0\n",
    "sol.loc[(sol['Solar_Elevation_Angle(deg)'] <= 85) & (sol['Solar_Elevation_Angle(deg)'] > 5), 'Approx_Atomospheric_Refraction'] = 58.1/np.tan(np.radians(sol['Solar_Elevation_Angle(deg)']))-0.07/pow(np.tan(np.radians(sol['Solar_Elevation_Angle(deg)'])),3) + 0.000086/pow(np.tan(np.radians(sol['Solar_Elevation_Angle(deg)'])),5)\n",
    "sol.loc[(sol['Solar_Elevation_Angle(deg)'] <= 5) & (sol['Solar_Elevation_Angle(deg)'] > -0.575), 'Approx_Atomospheric_Refraction'] = 1735+sol['Solar_Elevation_Angle(deg)']*(-518.2+sol['Solar_Elevation_Angle(deg)']*(103.4+sol['Solar_Elevation_Angle(deg)']*(-12.79+sol['Solar_Elevation_Angle(deg)']*0.711)))\n",
    "sol.loc[sol['Solar_Elevation_Angle(deg)'] <= -0.575, 'Approx_Atomospheric_Refraction'] = -20.772/np.tan(np.radians(sol['Solar_Elevation_Angle(deg)']))\n",
    "sol['Approx_Atomospheric_Refraction'] = sol['Approx_Atomospheric_Refraction']/3600\n",
    "\n",
    "# Solar Elevation Corrected (deg)\n",
    "sol['Solar_Elevation_corr(deg)'] = sol['Solar_Elevation_Angle(deg)'] + sol['Approx_Atomospheric_Refraction']\n",
    "\n",
    "# Solar Azimuth Angle (deg cw from N)\n",
    "sol['Solar_Azimuth_Angle(deg_cw_from_N)'] = np.nan\n",
    "sol.loc[sol['Hour_Angle(deg)'] > 0, 'Solar_Azimuth_Angle(deg_cw_from_N)'] = (np.degrees(np.arccos(((math.sin(math.radians(Latitude))*np.cos(np.radians(sol['Solar_Zenith_Angle(deg)'])))-np.sin(np.radians(sol['Sun_Declin(deg)'])))/(math.cos(math.radians(Latitude))*np.sin(np.radians(sol['Solar_Zenith_Angle(deg)'])))))+180) % 360\n",
    "sol.loc[sol['Hour_Angle(deg)'] <= 0, 'Solar_Azimuth_Angle(deg_cw_from_N)'] = (540-np.degrees(np.arccos(((math.sin(math.radians(Latitude))*np.cos(np.radians(sol['Solar_Zenith_Angle(deg)'])))-np.sin(np.radians(sol['Sun_Declin(deg)'])))/(math.cos(math.radians(Latitude))*np.sin(np.radians(sol['Solar_Zenith_Angle(deg)'])))))) % 360\n",
    "\n",
    "# Account for daylight savings\n",
    "if daylight_savings.lower() == 'yes':\n",
    "    start = datetime.strptime(start_day, '%Y-%m-%d')\n",
    "    end = datetime.strptime(end_day, '%Y-%m-%d')\n",
    "    sol.loc[(sol['Date'] <= end) & (sol['Date'] >= start), 'Solar_Noon(LST)'] = [tz_offset(x, 1) for x in sol.loc[(sol['Date'] <= end) & (sol['Date'] >= start), 'Solar_Noon(LST)']]\n",
    "    sol.loc[(sol['Date'] <= end) & (sol['Date'] >= start), 'Sunrise_Time(LST)'] = [tz_offset(x, 1) for x in sol.loc[(sol['Date'] <= end) & (sol['Date'] >= start), 'Sunrise_Time(LST)']]\n",
    "    sol.loc[(sol['Date'] <= end) & (sol['Date'] >= start), 'Sunset_Time(LST)'] = [tz_offset(x, 1) for x in sol.loc[(sol['Date'] <= end) & (sol['Date'] >= start), 'Sunset_Time(LST)']]\n",
    "else:\n",
    "    pass\n",
    "\n",
    "sol.set_index('Date', inplace=True)\n",
    "\n",
    "# Save to csv\n",
    "if daylight_savings.lower() == 'yes':\n",
    "    daylight_file = 'Daylight'\n",
    "else:\n",
    "    daylight_file = 'NoDaylight'\n",
    "filename = 'Solar_' + location + '_' + str(Latitude) + '_' + str(Longitude) + '_' + daylight_file + '.csv'\n",
    "sol.to_csv(filename, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hourly Averages or Other Weather Data\n",
    "Currently the program uses U.S. Hourly Climate Normals based on 30-year averages from 1981 to 2010 to calculate average weather values in addition to Photosynthetic Photon Flux. Other weather data can be substituted or weather data can be left off all together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in 30-year average weather data. The current example uses data for Salt Lake City."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T22:54:31.024184Z",
     "start_time": "2021-01-26T22:54:30.996176Z"
    }
   },
   "outputs": [],
   "source": [
    "filename = hourly_averages_filename + '.csv'\n",
    "hour_ave = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to datetime formats for indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T22:54:32.056405Z",
     "start_time": "2021-01-26T22:54:31.980381Z"
    }
   },
   "outputs": [],
   "source": [
    "if hourly_averages.lower() == 'yes':\n",
    "    hour_ave['DATE']=pd.to_datetime(hour_ave['DATE'], format='%m-%dT%H:%M:%S')\n",
    "    hour_ave['DATE']=hour_ave['DATE'].apply(lambda x: x.replace(year = year))\n",
    "    hour_ave.set_index('DATE', inplace=True)\n",
    "# elif daily_averages.lower() == 'yes':\n",
    "#     pass\n",
    "else:\n",
    "    averages_file = 'NoWeather'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T18:49:13.521433Z",
     "start_time": "2021-01-26T18:49:13.493424Z"
    }
   },
   "source": [
    "### Web Scraper\n",
    "Accesses the [Apogee Instrument's Clear Sky Calculator](http://clearskycalculator.com/quantumsensor.htm) to calculate Phososynthetic Photon Flux density."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T18:50:54.813299Z",
     "start_time": "2021-01-26T18:50:54.808309Z"
    }
   },
   "source": [
    "Create an instance of the web driver and open site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T22:54:40.823568Z",
     "start_time": "2021-01-26T22:54:37.107793Z"
    }
   },
   "outputs": [],
   "source": [
    "wd = webdriver.Chrome()\n",
    "wd.get('http://clearskycalculator.com/quantumsensor.htm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup locations to fill on webpage through Selenium interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T22:54:54.295699Z",
     "start_time": "2021-01-26T22:54:54.187678Z"
    }
   },
   "outputs": [],
   "source": [
    "Latitude_Input = wd.find_element_by_xpath('//*[@id=\"p1G6\"]')\n",
    "Longitude_Input = wd.find_element_by_xpath('//*[@id=\"p1G8\"]')\n",
    "Longitude_tz_Input = wd.find_element_by_xpath('//*[@id=\"p1G10\"]')\n",
    "Elevation_Input = wd.find_element_by_xpath('//*[@id=\"p1G12\"]')\n",
    "Day_Input = wd.find_element_by_xpath('//*[@id=\"p1G14\"]')\n",
    "Time_Input = wd.find_element_by_xpath('//*[@id=\"p1G16\"]')\n",
    "Daylight_Savings_Input = wd.find_element_by_xpath('//*[@id=\"p1G18\"]')\n",
    "Air_Temperature_Input = wd.find_element_by_xpath('//*[@id=\"p1G20\"]')\n",
    "Relative_Humidity = wd.find_element_by_xpath('//*[@id=\"p1G22\"]')\n",
    "Recalculate = wd.find_element_by_xpath('//*[@id=\"panel1\"]/table/tbody/tr[23]/td[3]/input')\n",
    "Estimated_PPF = wd.find_element_by_xpath('//*[@id=\"p1L6\"]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loops through all days and hours in a year to estimate PPF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T23:18:00.802778Z",
     "start_time": "2021-01-26T22:54:57.132272Z"
    }
   },
   "outputs": [],
   "source": [
    "#Initial inputs that set location for Apogee Scientific model\n",
    "Latitude_Input.send_keys(Keys.CONTROL,\"a\")\n",
    "Latitude_Input.send_keys(str(Latitude))\n",
    "\n",
    "Longitude_Input.send_keys(Keys.CONTROL,\"a\")\n",
    "Longitude_Input.send_keys(str(Longitude * -1))\n",
    "\n",
    "Longitude_tz_Input.send_keys(Keys.CONTROL,\"a\")\n",
    "Longitude_tz_Input.send_keys(str(Longitude_tz))\n",
    "\n",
    "Elevation_Input.send_keys(Keys.CONTROL,\"a\")\n",
    "Elevation_Input.send_keys(str(Elevation))\n",
    "\n",
    "Daylight_Savings_Input.send_keys(Keys.CONTROL,\"a\")\n",
    "if daylight_savings.lower() == 'yes':\n",
    "    Daylight_Savings_Input.send_keys('1')\n",
    "else:\n",
    "    Daylight_Savings_Input.send_keys('0')\n",
    "    \n",
    "#Create an array with headers to store values\n",
    "if hourly_averages.lower() == 'yes':\n",
    "    # Creates headers for photoperiod length, PPF, and Hourly Normals\n",
    "    weather_model = pd.DataFrame(columns = ['Date','Light(hours)','Dark(hours)','Estimated_PPF(umol/m^2*s^1)','Temperature(90th)','Temperature(mean)','Temperature(10th)','DewPoint(90th)','DewPoint(mean)','DewPoint(10th)','CloudsBroken','CloudsClear','CloudsScattered','CloudsOvercast','CloudsFew','RelativeHumidity'])\n",
    "else:\n",
    "    # Creates headers for photoperiod length and PPF\n",
    "    weather_model = pd.DataFrame(columns = ['Date','Light(hours)','Dark(hours)','Estimated_PPF(umol/m^2*s^1)'])\n",
    "\n",
    "for day in range(1,366):\n",
    "    #Create datetime variable from day number\n",
    "    date = dt.datetime(year, 1, 1) + dt.timedelta(day - 1)\n",
    "    \n",
    "    #Find light and dark durations\n",
    "    Light = sol.loc[date]['Sunlight_Duration(min)']\n",
    "    Dark = sol.loc[date]['Dark_Duration(min)']\n",
    "    \n",
    "    #Input webpage values\n",
    "    Day_Input.send_keys(Keys.CONTROL,\"a\")\n",
    "    Day_Input.send_keys(day)\n",
    "    \n",
    "    for hour in range(0,24):\n",
    "        #Convert hours to datetime format and add to date from first loop\n",
    "        hour = dt.timedelta(hours = hour)\n",
    "        date_time = date + hour\n",
    "        \n",
    "        if hourly_averages.lower() == 'yes':\n",
    "            # Incorporates Hourly Normals\n",
    "            try:\n",
    "                # Calculates using existing values\n",
    "                Hourly_Normals(date_time, hour_ave, weather_model)\n",
    "            except:\n",
    "                # Calulates using previous normals for gaps in data\n",
    "                try:\n",
    "                    offset = timedelta(days = -1)\n",
    "                    Hourly_Normals_Offset(date_time, hour_ave, weather_model, offset)\n",
    "                except:\n",
    "                    try:\n",
    "                        offset = timedelta(days = 1)\n",
    "                        Hourly_Normals_Offset(date_time, hour_ave, weather_model, offset)\n",
    "                    except:\n",
    "                        try:\n",
    "                            offset = timedelta(hours = -1)\n",
    "                            Hourly_Normals_Offset(date_time, hour_ave, weather_model, offset)\n",
    "                        except:\n",
    "                            offset = timedelta(hours = 1)\n",
    "                            Hourly_Normals_Offset(date_time, hour_ave, weather_model, offset)\n",
    "        elif daily_averages.lower() == 'yes':\n",
    "            # Incorporates Daily Normals\n",
    "            pass\n",
    "        else:\n",
    "            # Ignores Hourly Normals and assumes average values for temperature and humidity\n",
    "            pass\n",
    "\n",
    "# Format index of weather model\n",
    "weather_model['Date']=pd.to_datetime(weather_model['Date'], format='%Y-%m-%d %H:%M:%S')\n",
    "weather_model.set_index('Date', inplace=True)\n",
    "\n",
    "# Fill NaN values with 0\n",
    "weather_model.fillna(value=0,inplace=True)\n",
    "\n",
    "# Save weather model to csv file\n",
    "if daylight_savings.lower() == 'yes':\n",
    "    daylight_file = 'Daylight'\n",
    "else:\n",
    "    daylight_file = 'NoDaylight'\n",
    "\n",
    "if hourly_averages.lower() == 'yes':\n",
    "    averages_file = 'Hourly_' + hourly_location_averages\n",
    "# elif daily_averages.lower() == 'yes':\n",
    "#     averages_file = 'Daily_' + daily_location_averages\n",
    "else:\n",
    "    averages_file = 'NoWeather'\n",
    "    \n",
    "filename = 'PPF_' + location + '_' + str(Latitude) + '_' + str(Longitude) + '_' + daylight_file + '_' + averages_file + '.csv'\n",
    "weather_model.to_csv(filename, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
